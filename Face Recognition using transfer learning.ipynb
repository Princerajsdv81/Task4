{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "#VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "#Load the VGG16 model \n",
    "model = VGG16(weights = 'imagenet' ,\n",
    "             include_top = False ,\n",
    "             input_shape = (img_rows ,img_cols , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D True\n",
      "2 Conv2D True\n",
      "3 MaxPooling2D True\n",
      "4 Conv2D True\n",
      "5 Conv2D True\n",
      "6 MaxPooling2D True\n",
      "7 Conv2D True\n",
      "8 Conv2D True\n",
      "9 Conv2D True\n",
      "10 MaxPooling2D True\n",
      "11 Conv2D True\n",
      "12 Conv2D True\n",
      "13 Conv2D True\n",
      "14 MaxPooling2D True\n",
      "15 Conv2D True\n",
      "16 Conv2D True\n",
      "17 Conv2D True\n",
      "18 MaxPooling2D True\n"
     ]
    }
   ],
   "source": [
    "#Now print our layers\n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i) + \" \" + layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModel(bottom_model , num_classes):\n",
    "    \"\"\"creates the top or the head of the model that will be\n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation ='relu')(top_model)\n",
    "    top_model = Dense(512,activation ='relu')(top_model)\n",
    "    top_model = Dense(248,activation ='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation ='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 248)               127224    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1245      \n",
      "=================================================================\n",
      "Total params: 15,893,269\n",
      "Trainable params: 15,893,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense ,Dropout,Activation,Flatten,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D,MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "num_classes = 5\n",
    "\n",
    "FC_head =addTopModel(model, num_classes)\n",
    "modelnew= Model(inputs =model.input ,outputs =FC_head)\n",
    "print(modelnew.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 5 classes.\n",
      "Found 25 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir ='C:/Users/Prince Raj/Desktop/task4/train/'\n",
    "validation_data_dir ='C:/Users/Prince Raj/Desktop/task4/val/'\n",
    "    \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale =1./255,\n",
    "      rotation_range =20,\n",
    "      width_shift_range = 0.2,\n",
    "      horizontal_flip = True,\n",
    "      fill_mode ='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale =1.255)\n",
    "                 \n",
    "#change the batchsize according to your system RAM\n",
    "train_batchsize =15\n",
    "val_batchsize =10\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "         train_data_dir ,\n",
    "         target_size =(img_rows,img_cols),\n",
    "         batch_size = train_batchsize ,\n",
    "         class_mode ='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "          validation_data_dir,\n",
    "          target_size = (img_rows,img_cols),\n",
    "          batch_size =val_batchsize ,\n",
    "          class_mode = 'categorical',\n",
    "          shuffle = False)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.7609 - accuracy: 0.7659 - val_loss: 6.1348 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.13484, saving model to data.h5\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.5156 - accuracy: 0.8000 - val_loss: 6.1348 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 6.13484\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 17s 2s/step - loss: 0.5082 - accuracy: 0.8000 - val_loss: 2.6639e-04 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.13484 to 0.00027, saving model to data.h5\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.5674 - accuracy: 0.7874 - val_loss: 0.6398 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00027\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.5142 - accuracy: 0.8000 - val_loss: 3.0271 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00027\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.5016 - accuracy: 0.8000 - val_loss: 0.0926 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00027\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint ,EarlyStopping\n",
    "\n",
    "checkpoint= ModelCheckpoint(\"data.h5\",\n",
    "                            monitor= \"val_loss\",\n",
    "                            \n",
    "                            mode =\"min\",\n",
    "                            save_best_only =True,\n",
    "                            verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                         min_delta=0,\n",
    "                         patience=3,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "#we will going to put our call backs into callback list\n",
    "callbacks = [checkpoint,earlystop]\n",
    "\n",
    "#Now we use a very small lerarning rate\n",
    "modelnew.compile(loss ='binary_crossentropy',\n",
    "                optimizer =Adam(lr=0.001),\n",
    "                metrics=['accuracy'])\n",
    "nb_train_samples =91\n",
    "nb_validation_samples =24\n",
    "epochs =10 \n",
    "batch_size =10\n",
    "history=modelnew.fit_generator(train_generator,\n",
    "                            \n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "modelnew.save(\"data.h5\")\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class - Ben Afflek\n",
      "class - Ben Afflek\n",
      "class - Ben Afflek\n",
      "class - Jerry Seinfeld\n",
      "class - Ben Afflek\n",
      "class - Ben Afflek\n",
      "class - Ben Afflek\n",
      "class - Ben Afflek\n",
      "class - Ben Afflek\n",
      "class - Elton John\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "classifier=load_model('data.h5')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile ,join\n",
    "from random import *\n",
    "\n",
    "dict ={\"[0]\":\"Ben Afflek\",\n",
    "           \"[1]\":\"Elton John\",\n",
    "           \"[2]\":\"Jerry Seinfeld\",\n",
    "           \"[3]\":\"Madonna\",\n",
    "           \"[4]\":\"Mindy Kaling\"}\n",
    "dict_n ={\"ben_afflek\":\"Ben Afflek\",\n",
    "        \"elton_john\":\"Elton John\",\n",
    "        \"jerry_seinfeld\":\"Jerry Seinfeld\",\n",
    "        \"madonna\":\"Madonna\",\n",
    "        \"mindy_kaling\":\"Mindy kaling\"}\n",
    "def draw_test(name,pred,im):\n",
    "    Celebrity = dict[str(pred)]\n",
    "    BLACK =[0,0,0]\n",
    "    expand_image=cv2.CopyMakeBorder(im,80,0,0,100,cv2.BORDER_CONSTANT, value =BLACK)\n",
    "    cv2.putText(expanded_image,Celebrity,(20,60),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.imshow(name,expanded_image)\n",
    "    \n",
    "def getImage(path):\n",
    "    \"\"\"function load a random images from a random folder in our test path\"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path,x)) ,os.listdir(path)))\n",
    "    random_directory =np.random.randint(0,len(folders))\n",
    "    path_class=folders[random_directory]\n",
    "    print(\"class - \" + dict_n[str(path_class)])\n",
    "    \n",
    "    file_path=path + path_class\n",
    "    file_names =[f for f in listdir(file_path) if isfile(join(file_path,f))]\n",
    "    random_file_index=np.random.randint(0 ,len(file_names))\n",
    "    image_name =file_names[random_file_index]\n",
    "    return cv2.imread(file_path + \"/\" + image_name)\n",
    "\n",
    "for i in range (0,10):\n",
    "    input_im = getImage(\"C:/Users/Prince Raj/Desktop/task4/val/\")\n",
    "    input_original =input_im.copy()\n",
    "    input_original =cv2.resize(input_original,None,fx=0.5,fy=0.5,interpolation =cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im =cv2.resize(input_im,(64,64),interpolation=cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 225.\n",
    "    input_im =input_im.reshape(1,64,64,3)\n",
    "    \n",
    "    #Get prediction\n",
    "    res =np.argmax(classifier.predict(input_im,1,verbose=0), axis =1)\n",
    "    \n",
    "    #Show image with predicted class\n",
    "    draw_test=(\"prediction\",res ,input_original)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
